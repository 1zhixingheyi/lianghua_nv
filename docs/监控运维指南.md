# 量化交易系统监控运维指南

## 📋 概述

本指南详细介绍量化交易系统的监控运维方案，包括系统监控、性能监控、业务监控、告警机制、日志管理、故障处理等内容，确保系统稳定可靠运行。

## 🎯 监控体系架构

### 监控层次结构

```
监控体系
├── 基础设施监控
│   ├── 服务器资源监控
│   ├── 网络监控
│   └── 存储监控
├── 中间件监控
│   ├── 数据库监控
│   ├── Redis监控
│   └── 消息队列监控
├── 应用监控
│   ├── 服务可用性监控
│   ├── API性能监控
│   └── 业务指标监控
└── 业务监控
    ├── 交易监控
    ├── 策略监控
    └── 风控监控
```

### 监控技术栈

- **数据收集**: Prometheus + Node Exporter + Custom Exporters
- **数据存储**: Prometheus + InfluxDB
- **可视化**: Grafana + Custom Dashboard
- **告警**: AlertManager + 钉钉/邮件/短信
- **日志**: ELK Stack (Elasticsearch + Logstash + Kibana)
- **链路追踪**: Jaeger
- **性能监控**: APM (Application Performance Monitoring)

## 🔧 监控系统部署

### 1. Prometheus配置

#### 安装和配置

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./config/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    restart: unless-stopped

volumes:
  prometheus_data:
```

#### Prometheus配置文件

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # 系统监控
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # 应用监控
  - job_name: 'lianghua-app'
    static_configs:
      - targets: ['app:5000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # MySQL监控
  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  # Redis监控
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginx监控
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

### 2. 自定义应用监控

#### Flask应用指标暴露

```python
# monitor/metrics.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from flask import Response
import time
import psutil
import functools

# 定义指标
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_LATENCY = Histogram('http_request_duration_seconds', 'HTTP request latency')
ACTIVE_CONNECTIONS = Gauge('active_connections_total', 'Active WebSocket connections')
STRATEGY_PERFORMANCE = Gauge('strategy_performance', 'Strategy performance metrics', ['strategy_name', 'metric_type'])
ORDER_COUNT = Counter('orders_total', 'Total orders placed', ['symbol', 'side', 'status'])
PORTFOLIO_VALUE = Gauge('portfolio_value_total', 'Total portfolio value')
SYSTEM_CPU = Gauge('system_cpu_percent', 'System CPU usage percentage')
SYSTEM_MEMORY = Gauge('system_memory_percent', 'System memory usage percentage')

class MetricsCollector:
    """指标收集器"""
    
    def __init__(self):
        self.start_time = time.time()
        
    def track_request(self, method, endpoint, status_code, duration):
        """记录HTTP请求指标"""
        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status=status_code).inc()
        REQUEST_LATENCY.observe(duration)
        
    def track_order(self, symbol, side, status):
        """记录订单指标"""
        ORDER_COUNT.labels(symbol=symbol, side=side, status=status).inc()
        
    def update_portfolio_value(self, value):
        """更新投资组合价值"""
        PORTFOLIO_VALUE.set(value)
        
    def update_strategy_performance(self, strategy_name, metric_type, value):
        """更新策略性能指标"""
        STRATEGY_PERFORMANCE.labels(strategy_name=strategy_name, metric_type=metric_type).set(value)
        
    def update_system_metrics(self):
        """更新系统指标"""
        SYSTEM_CPU.set(psutil.cpu_percent())
        SYSTEM_MEMORY.set(psutil.virtual_memory().percent)
        
    def track_websocket_connection(self, increment=True):
        """跟踪WebSocket连接"""
        if increment:
            ACTIVE_CONNECTIONS.inc()
        else:
            ACTIVE_CONNECTIONS.dec()

# 全局指标收集器实例
metrics_collector = MetricsCollector()

def monitor_requests(f):
    """请求监控装饰器"""
    @functools.wraps(f)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            response = f(*args, **kwargs)
            status_code = getattr(response, 'status_code', 200)
        except Exception as e:
            status_code = 500
            raise
        finally:
            duration = time.time() - start_time
            from flask import request
            metrics_collector.track_request(
                request.method,
                request.endpoint or 'unknown',
                status_code,
                duration
            )
            
        return response
    return wrapper

@app.route('/metrics')
def metrics():
    """Prometheus指标端点"""
    # 更新系统指标
    metrics_collector.update_system_metrics()
    
    # 生成Prometheus格式的指标
    return Response(generate_latest(), mimetype='text/plain')
```

#### 业务指标监控

```python
# monitor/business_metrics.py
import threading
import time
from datetime import datetime, timedelta
from data.database import get_database_manager
from .metrics import metrics_collector

class BusinessMetricsCollector:
    """业务指标收集器"""
    
    def __init__(self):
        self.db = get_database_manager()
        self.running = False
        self.collection_thread = None
        
    def start_collection(self):
        """启动指标收集"""
        if self.running:
            return
            
        self.running = True
        self.collection_thread = threading.Thread(target=self._collection_loop)
        self.collection_thread.daemon = True
        self.collection_thread.start()
        
    def stop_collection(self):
        """停止指标收集"""
        self.running = False
        if self.collection_thread:
            self.collection_thread.join()
            
    def _collection_loop(self):
        """指标收集循环"""
        while self.running:
            try:
                # 收集业务指标
                self._collect_portfolio_metrics()
                self._collect_strategy_metrics()
                self._collect_trading_metrics()
                self._collect_risk_metrics()
                
                # 每30秒收集一次
                time.sleep(30)
                
            except Exception as e:
                print(f"业务指标收集错误: {e}")
                time.sleep(60)
                
    def _collect_portfolio_metrics(self):
        """收集投资组合指标"""
        try:
            # 获取当前投资组合价值
            portfolio_value = self._get_portfolio_value()
            metrics_collector.update_portfolio_value(portfolio_value)
            
            # 计算日收益率
            daily_return = self._calculate_daily_return()
            metrics_collector.update_strategy_performance('portfolio', 'daily_return', daily_return)
            
        except Exception as e:
            print(f"投资组合指标收集失败: {e}")
            
    def _collect_strategy_metrics(self):
        """收集策略指标"""
        try:
            strategies = self._get_active_strategies()
            
            for strategy in strategies:
                # 策略收益率
                returns = self._calculate_strategy_returns(strategy['id'])
                metrics_collector.update_strategy_performance(
                    strategy['name'], 'total_return', returns
                )
                
                # 策略仓位
                position_ratio = self._get_strategy_position_ratio(strategy['id'])
                metrics_collector.update_strategy_performance(
                    strategy['name'], 'position_ratio', position_ratio
                )
                
                # 策略状态
                status = 1 if strategy['status'] == 'active' else 0
                metrics_collector.update_strategy_performance(
                    strategy['name'], 'status', status
                )
                
        except Exception as e:
            print(f"策略指标收集失败: {e}")
            
    def _collect_trading_metrics(self):
        """收集交易指标"""
        try:
            today = datetime.now().date()
            
            # 今日订单统计
            order_stats = self._get_daily_order_stats(today)
            for symbol, stats in order_stats.items():
                for side, count in stats.items():
                    # 这里只更新计数，实际订单在下单时记录
                    pass
                    
            # 成交统计
            execution_stats = self._get_execution_stats(today)
            metrics_collector.update_strategy_performance(
                'trading', 'execution_rate', execution_stats['execution_rate']
            )
            
        except Exception as e:
            print(f"交易指标收集失败: {e}")
            
    def _collect_risk_metrics(self):
        """收集风控指标"""
        try:
            # 当前回撤
            current_drawdown = self._calculate_current_drawdown()
            metrics_collector.update_strategy_performance('risk', 'current_drawdown', current_drawdown)
            
            # 仓位集中度
            position_concentration = self._calculate_position_concentration()
            metrics_collector.update_strategy_performance('risk', 'position_concentration', position_concentration)
            
            # 风险预算使用率
            risk_budget_usage = self._calculate_risk_budget_usage()
            metrics_collector.update_strategy_performance('risk', 'risk_budget_usage', risk_budget_usage)
            
        except Exception as e:
            print(f"风控指标收集失败: {e}")
            
    def _get_portfolio_value(self) -> float:
        """获取投资组合价值"""
        # 实现投资组合价值计算
        return 1000000.0  # 示例值
        
    def _calculate_daily_return(self) -> float:
        """计算日收益率"""
        # 实现日收益率计算
        return 0.01  # 示例值
        
    def _get_active_strategies(self) -> list:
        """获取活跃策略列表"""
        # 从数据库获取活跃策略
        return [
            {'id': 1, 'name': 'RSI_Strategy', 'status': 'active'},
            {'id': 2, 'name': 'MACD_Strategy', 'status': 'active'}
        ]
        
    def _calculate_strategy_returns(self, strategy_id: int) -> float:
        """计算策略收益率"""
        # 实现策略收益率计算
        return 0.05  # 示例值
        
    def _get_strategy_position_ratio(self, strategy_id: int) -> float:
        """获取策略仓位比例"""
        # 实现仓位比例计算
        return 0.8  # 示例值
        
    def _get_daily_order_stats(self, date) -> dict:
        """获取日订单统计"""
        # 实现订单统计
        return {}
        
    def _get_execution_stats(self, date) -> dict:
        """获取成交统计"""
        # 实现成交统计
        return {'execution_rate': 0.95}
        
    def _calculate_current_drawdown(self) -> float:
        """计算当前回撤"""
        # 实现回撤计算
        return -0.05  # 示例值
        
    def _calculate_position_concentration(self) -> float:
        """计算仓位集中度"""
        # 实现集中度计算
        return 0.3  # 示例值
        
    def _calculate_risk_budget_usage(self) -> float:
        """计算风险预算使用率"""
        # 实现风险预算计算
        return 0.6  # 示例值

# 全局业务指标收集器
business_metrics = BusinessMetricsCollector()
```

### 3. 告警规则配置

#### Prometheus告警规则

```yaml
# config/rules/system_alerts.yml
groups:
  - name: system_alerts
    rules:
      # 系统资源告警
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% for more than 5 minutes"

      - alert: HighMemoryUsage
        expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Available memory is below 10%"

      - alert: DiskSpaceLow
        expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk space is below 10%"

  - name: application_alerts
    rules:
      # 应用服务告警
      - alert: ApplicationDown
        expr: up{job="lianghua-app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Application is down"
          description: "Lianghua application has been down for more than 1 minute"

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, http_request_duration_seconds_bucket) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is above 5 seconds"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate"
          description: "Error rate is above 10%"

  - name: business_alerts
    rules:
      # 业务告警
      - alert: HighDrawdown
        expr: strategy_performance{metric_type="current_drawdown"} < -0.15
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "High portfolio drawdown"
          description: "Portfolio drawdown exceeds 15%"

      - alert: StrategyDown
        expr: strategy_performance{metric_type="status"} == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Strategy is inactive"
          description: "Strategy {{ $labels.strategy_name }} has been inactive for 5 minutes"

      - alert: LowExecutionRate
        expr: strategy_performance{metric_type="execution_rate"} < 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Low order execution rate"
          description: "Order execution rate is below 80%"
```

#### AlertManager配置

```yaml
# config/alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@lianghua.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'default'
    webhook_configs:
      - url: 'http://localhost:5000/webhook/alerts'

  - name: 'critical-alerts'
    email_configs:
      - to: 'admin@lianghua.com'
        subject: 'CRITICAL: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ range .Labels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}
          {{ end }}
    webhook_configs:
      - url: 'http://localhost:5000/webhook/critical'

  - name: 'warning-alerts'
    webhook_configs:
      - url: 'http://localhost:5000/webhook/warning'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

### 4. Grafana仪表板

#### 系统监控仪表板

```json
{
  "dashboard": {
    "id": null,
    "title": "量化交易系统监控",
    "tags": ["lianghua", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "系统概览",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"lianghua-app\"}",
            "legendFormat": "应用状态"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "green", "value": 1}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "CPU使用率",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU使用率"
          }
        ],
        "yAxes": [
          {
            "min": 0,
            "max": 100,
            "unit": "percent"
          }
        ]
      },
      {
        "id": 3,
        "title": "内存使用率",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100",
            "legendFormat": "内存使用率"
          }
        ]
      },
      {
        "id": 4,
        "title": "HTTP请求量",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "id": 5,
        "title": "响应时间",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds_bucket)",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, http_request_duration_seconds_bucket)",
            "legendFormat": "50th percentile"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

#### 业务监控仪表板

```json
{
  "dashboard": {
    "title": "业务监控仪表板",
    "panels": [
      {
        "id": 1,
        "title": "投资组合价值",
        "type": "stat",
        "targets": [
          {
            "expr": "portfolio_value_total",
            "legendFormat": "总价值"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "currency",
            "decimals": 2
          }
        }
      },
      {
        "id": 2,
        "title": "策略收益率",
        "type": "graph",
        "targets": [
          {
            "expr": "strategy_performance{metric_type=\"total_return\"}",
            "legendFormat": "{{strategy_name}}"
          }
        ]
      },
      {
        "id": 3,
        "title": "当前回撤",
        "type": "gauge",
        "targets": [
          {
            "expr": "strategy_performance{metric_type=\"current_drawdown\"}",
            "legendFormat": "回撤"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": -50,
            "max": 0,
            "thresholds": {
              "steps": [
                {"color": "green", "value": -5},
                {"color": "yellow", "value": -10},
                {"color": "red", "value": -20}
              ]
            }
          }
        }
      },
      {
        "id": 4,
        "title": "订单统计",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(orders_total[5m])",
            "legendFormat": "{{side}} orders"
          }
        ]
      },
      {
        "id": 5,
        "title": "策略状态",
        "type": "table",
        "targets": [
          {
            "expr": "strategy_performance{metric_type=\"status\"}",
            "format": "table"
          }
        ]
      }
    ]
  }
}
```

## 📊 日志管理

### 1. 日志收集配置

#### ELK Stack部署

```yaml
# docker-compose.elk.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:7.14.0
    container_name: logstash
    ports:
      - "5044:5044"
    volumes:
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
      - ./config/logstash/config:/usr/share/logstash/config
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:7.14.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.14.0
    container_name: filebeat
    volumes:
      - ./config/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log:ro
      - ./logs:/app/logs:ro
    depends_on:
      - logstash

volumes:
  elasticsearch_data:
```

#### Filebeat配置

```yaml
# config/filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /app/logs/*.log
    fields:
      service: lianghua-trading
      environment: production
    fields_under_root: true
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after

  - type: log
    enabled: true
    paths:
      - /var/log/nginx/access.log
    fields:
      service: nginx
      log_type: access

  - type: log
    enabled: true
    paths:
      - /var/log/nginx/error.log
    fields:
      service: nginx
      log_type: error

output.logstash:
  hosts: ["logstash:5044"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
```

#### Logstash配置

```ruby
# config/logstash/pipeline/logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [service] == "lianghua-trading" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{WORD:logger} - %{WORD:level} - %{GREEDYDATA:log_message}" 
      }
    }
    
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS" ]
    }
    
    if [level] == "ERROR" {
      mutate {
        add_tag => [ "error" ]
      }
    }
  }
  
  if [service] == "nginx" and [log_type] == "access" {
    grok {
      match => { 
        "message" => "%{NGINXACCESS}" 
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{service}-%{+YYYY.MM.dd}"
  }
  
  # 错误日志同时输出到告警
  if "error" in [tags] {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "alerts" => [
          {
            "labels" => {
              "alertname" => "ApplicationError"
              "service" => "%{service}"
              "severity" => "warning"
            }
            "annotations" => {
              "summary" => "Application error detected"
              "description" => "%{log_message}"
            }
          }
        ]
      }
    }
  }
}
```

### 2. 结构化日志

#### 应用日志格式化

```python
# utils/logging_config.py
import logging
import json
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON格式的日志格式化器"""
    
    def format(self, record):
        log_entry = {
            'timestamp': datetime.fromtimestamp(record.created).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        # 添加额外字段
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
        if hasattr(record, 'strategy_id'):
            log_entry['strategy_id'] = record.strategy_id
            
        # 异常信息
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
            
        return json.dumps(log_entry, ensure_ascii=False)

class ContextFilter(logging.Filter):
    """上下文过滤器，添加请求ID等信息"""
    
    def filter(self, record):
        # 从Flask上下文获取请求ID
        try:
            from flask import g
            if hasattr(g, 'request_id'):
                record.request_id = g.request_id
        except:
            pass
            
        return True

def setup_logging(app_name: str, log_level: str = 'INFO'):
    """设置应用日志"""
    
    # 创建根日志器
    logger = logging.getLogger(app_name)
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # 清除现有处理器
    logger.handlers.clear()
    
    # 控制台处理器
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(JSONFormatter())
    console_handler.addFilter(ContextFilter())
    logger.addHandler(console_handler)
    
    # 文件处理器
    from logging.handlers import RotatingFileHandler
    file_handler = RotatingFileHandler(
        f'logs/{app_name}.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    file_handler.setFormatter(JSONFormatter())
    file_handler.addFilter(ContextFilter())
    logger.addHandler(file_handler)
    
    # 错误文件处理器
    error_handler = RotatingFileHandler(
        f'logs/{app_name}-error.log',
        maxBytes=10*1024*1024,
        backupCount=5
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(JSONFormatter())
    error_handler.addFilter(ContextFilter())
    logger.addHandler(error_handler)
    
    return logger

# 业务日志记录器
def log_business_event(event_type: str, details: Dict[str, Any], logger: logging.Logger):
    """记录业务事件"""
    log_data = {
        'event_type': event_type,
        'details': details,
        'timestamp': datetime.now().isoformat()
    }
    
    logger.info(f"BUSINESS_EVENT: {json.dumps(log_data)}")

def log_trading_event(action: str, symbol: str, quantity: int, price: float, 
                     strategy: str, logger: logging.Logger):
    """记录交易事件"""
    trading_data = {
        'action': action,
        'symbol': symbol,
        'quantity': quantity,
        'price': price,
        'strategy': strategy,
        'value': abs(quantity * price)
    }
    
    log_business_event('trading', trading_data, logger)

def log_risk_event(risk_type: str, severity: str, details: Dict[str, Any], 
                  logger: logging.Logger):
    """记录风控事件"""
    risk_data = {
        'risk_type': risk_type,
        'severity': severity,
        'details': details
    }
    
    log_business_event('risk', risk_data, logger)
```

## 🚨 告警机制

### 1. 告警通知配置

#### 钉钉机器人集成

```python
# utils/alert_handlers.py
import requests
import json
from typing import Dict, List
import logging

class DingTalkNotifier:
    """钉钉通知器"""
    
    def __init__(self, webhook_url: str, secret: str = None):
        self.webhook_url = webhook_url
        self.secret = secret
        self.logger = logging.getLogger(__name__)
        
    def send_message(self, title: str, content: str, at_mobiles: List[str] = None):
        """发送钉钉消息"""
        try:
            payload = {
                "msgtype": "markdown",
                "markdown": {
                    "title": title,
                    "text": content
                }
            }
            
            if at_mobiles:
                payload["at"] = {
                    "atMobiles": at_mobiles,
                    "isAtAll": False
                }
                
            # 如果有密钥，计算签名
            if self.secret:
                import time
                import hmac
                import hashlib
                import base64
                from urllib.parse import quote_plus
                
                timestamp = str(round(time.time() * 1000))
                secret_enc = self.secret.encode('utf-8')
                string_to_sign = f'{timestamp}\n{self.secret}'
                string_to_sign_enc = string_to_sign.encode('utf-8')
                hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()
                sign = quote_plus(base64.b64encode(hmac_code))
                
                url = f"{self.webhook_url}&timestamp={timestamp}&sign={sign}"
            else:
                url = self.webhook_url
                
            response = requests.post(url, json=payload, timeout=10)
            response.raise_for_status()
            
            self.logger.info(f"钉钉消息发送成功: {title}")
            
        except Exception as e:
            self.logger.error(f"钉钉消息发送失败: {e}")

class AlertManager:
    """告警管理器"""
    
    def __init__(self):
        self.notifiers = {}
        self.alert_rules = {}
        self.logger = logging.getLogger(__name__)
        
    def add_notifier(self, name: str, notifier):
        """添加通知器"""
        self.notifiers[name] = notifier
        
    def add_rule(self, rule_name: str, condition: callable, 
                 severity: str, notifiers: List[str]):
        """添加告警规则"""
        self.alert_rules[rule_name] = {
            'condition': condition,
            'severity': severity,
            'notifiers': notifiers,
            'last_triggered': None
        }
        
    def check_alerts(self, metrics: Dict[str, float]):
        """检查告警条件"""
        current_time = datetime.now()
        
        for rule_name, rule in self.alert_rules.items():
            try:
                if rule['condition'](metrics):
                    # 避免重复告警（5分钟内）
                    if (rule['last_triggered'] and 
                        (current_time - rule['last_triggered']).seconds < 300):
                        continue
                        
                    self._trigger_alert(rule_name, rule, metrics)
                    rule['last_triggered'] = current_time
                    
            except Exception as e:
                self.logger.error(f"告警规则检查失败 {rule_name}: {e}")
                
    def _trigger_alert(self, rule_name: str, rule: Dict, metrics: Dict):
        """触发告警"""
        severity = rule['severity']
        message = self._format_alert_message(rule_name, severity, metrics)
        
        # 发送通知
        for notifier_name in rule['notifiers']:
            if notifier_name in self.notifiers:
                try:
                    notifier = self.notifiers[notifier_name]
                    if hasattr(notifier, 'send_message'):
                        notifier.send_message(
                            f"【{severity.upper()}】{rule_name}",
                            message
                        )
                except Exception as e:
                    self.logger.error(f"发送告警通知失败 {notifier_name}: {e}")
                    
    def _format_alert_message(self, rule_name: str, severity: str, 
                            metrics: Dict) -> str:
        """格式化告警消息"""
        return f"""
### 🚨 系统告警

**告警规则**: {rule_name}  
**严重级别**: {severity}  
**触发时间**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  

**当前指标**:  
{chr(10).join([f"- {k}: {v}" for k, v in metrics.items()])}

**处理建议**:  
请立即检查系统状态并采取相应措施。
        """

# 示例告警规则配置
def setup_alert_rules():
    """设置告警规则"""
    alert_manager = AlertManager()
    
    # 添加钉钉通知器
    dingtalk = DingTalkNotifier(
        webhook_url="https://oapi.dingtalk.com/robot/send?access_token=xxx",
        secret="your_secret"
    )
    alert_manager.add_notifier('dingtalk', dingtalk)
    
    # CPU使用率告警
    alert_manager.add_rule(
        'high_cpu_usage',
        lambda m: m.get('cpu_percent', 0) > 80,
        'warning',
        ['dingtalk']
    )
    
    # 内存使用率告警
    alert_manager.add_rule(
        'high_memory_usage',
        lambda m: m.get('memory_percent', 0) > 85,
        'critical',
        ['dingtalk']
    )
    
    # 应用响应时间告警
    alert_manager.add_rule(
        'slow_response',
        lambda m: m.get('response_time_p95', 0) > 5,
        'warning',
        ['dingtalk']
    )
    
    # 策略回撤告警
    alert_manager.add_rule(
        'high_drawdown',
        lambda m: m.get('portfolio_drawdown', 0) < -0.15,
        'critical',
        ['dingtalk']
    )
    
    return alert_manager
```

### 2. 告警处理流程

#### 告警升级机制

```python
# utils/alert_escalation.py
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List
import logging

class AlertSeverity(Enum):
    INFO = 1
    WARNING = 2
    CRITICAL = 3
    EMERGENCY = 4

class AlertStatus(Enum):
    OPEN = "open"
    ACKNOWLEDGED = "acknowledged"
    RESOLVED = "resolved"

class Alert:
    """告警对象"""
    
    def __init__(self, alert_id: str, rule_name: str, severity: AlertSeverity,
                 message: str, metrics: Dict):
        self.alert_id = alert_id
        self.rule_name = rule_name
        self.severity = severity
        self.message = message
        self.metrics = metrics
        self.status = AlertStatus.OPEN
        self.created_at = datetime.now()
        self.acknowledged_at = None
        self.resolved_at = None
        self.escalation_level = 0
        
    def acknowledge(self):
        """确认告警"""
        self.status = AlertStatus.ACKNOWLEDGED
        self.acknowledged_at = datetime.now()
        
    def resolve(self):
        """解决告警"""
        self.status = AlertStatus.RESOLVED
        self.resolved_at = datetime.now()

class AlertEscalationManager:
    """告警升级管理器"""
    
    def __init__(self):
        self.active_alerts: Dict[str, Alert] = {}
        self.escalation_rules = {}
        self.on_call_schedule = {}
        self.logger = logging.getLogger(__name__)
        
    def add_escalation_rule(self, severity: AlertSeverity, escalation_steps: List[Dict]):
        """添加升级规则
        
        Args:
            severity: 告警级别
            escalation_steps: 升级步骤列表
                [
                    {'delay_minutes': 5, 'contacts': ['team@company.com']},
                    {'delay_minutes': 15, 'contacts': ['manager@company.com']},
                    {'delay_minutes': 30, 'contacts': ['director@company.com']}
                ]
        """
        self.escalation_rules[severity] = escalation_steps
        
    def process_alert(self, alert: Alert):
        """处理新告警"""
        self.active_alerts[alert.alert_id] = alert
        
        # 立即发送首次通知
        self._send_initial_notification(alert)
        
        # 启动升级流程
        self._start_escalation(alert)
        
    def _send_initial_notification(self, alert: Alert):
        """发送初始通知"""
        contacts = self._get_primary_contacts(alert.severity)
        self._send_notification(alert, contacts, escalation_level=0)
        
    def _start_escalation(self, alert: Alert):
        """启动升级流程"""
        if alert.severity not in self.escalation_rules:
            return
            
        import threading
        
        def escalation_worker():
            escalation_steps = self.escalation_rules[alert.severity]
            
            for step_index, step in enumerate(escalation_steps):
                # 等待指定时间
                import time
                time.sleep(step['delay_minutes'] * 60)
                
                # 检查告警是否已被确认或解决
                current_alert = self.active_alerts.get(alert.alert_id)
                if not current_alert or current_alert.status != AlertStatus.OPEN:
                    break
                    
                # 升级通知
                current_alert.escalation_level = step_index + 1
                self._send_notification(current_alert, step['contacts'], 
                                      escalation_level=step_index + 1)
                
        thread = threading.Thread(target=escalation_worker)
        thread.daemon = True
        thread.start()
        
    def _get_primary_contacts(self, severity: AlertSeverity) -> List[str]:
        """获取主要联系人"""
        if severity == AlertSeverity.CRITICAL or severity == AlertSeverity.EMERGENCY:
            return ['oncall@company.com']
        else:
            return ['team@company.com']
            
    def _send_notification(self, alert: Alert, contacts: List[str], 
                          escalation_level: int):
        """发送通知"""
        escalation_text = f" (升级等级: {escalation_level})" if escalation_level > 0 else ""
        
        message = f"""
🚨 系统告警{escalation_text}

告警ID: {alert.alert_id}
规则名称: {alert.rule_name}
严重程度: {alert.severity.name}
创建时间: {alert.created_at.strftime('%Y-%m-%d %H:%M:%S')}
状态: {alert.status.value}

详细信息:
{alert.message}

当前指标:
{self._format_metrics(alert.metrics)}

请及时处理此告警。
        """
        
        # 这里实现实际的通知发送逻辑
        self.logger.info(f"发送告警通知到: {contacts}")
        print(message)  # 示例输出
        
    def _format_metrics(self, metrics: Dict) -> str:
        """格式化指标信息"""
        return '\n'.join([f"- {k}: {v}" for k, v in metrics.items()])
        
    def acknowledge_alert(self, alert_id: str, acknowledged_by: str):
        """确认告警"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.acknowledge()
            
            self.logger.info(f"告警 {alert_id} 被 {acknowledged_by} 确认")
            
    def resolve_alert(self, alert_id: str, resolved_by: str):
        """解决告警"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.resolve()
            
            # 从活跃告警中移除
            del self.active_alerts[alert_id]
            
            self.logger.info(f"告警 {alert_id} 被 {resolved_by} 解决")
            
    def get_active_alerts(self) -> List[Alert]:
        """获取活跃告警列表"""
        return list(self.active_alerts.values())
```

## 📈 性能监控

### 1. 应用性能监控

#### APM集成

```python
# monitor/apm.py
import time
import psutil
import threading
from contextlib import contextmanager
from typing import Dict, Any
from collections import defaultdict, deque
import statistics

class PerformanceTracker:
    """性能跟踪器"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.metrics = defaultdict(lambda: deque(maxlen=window_size))
        self.counters = defaultdict(int)
        self.lock = threading.Lock()
        
    @contextmanager
    def track_execution_time(self, operation_name: str):
        """跟踪执行时间的上下文管理器"""
        start_time = time.time()
        try:
            yield
        finally:
            end_time = time.time()
            execution_time = end_time - start_time
            
            with self.lock:
                self.metrics[f"{operation_name}_duration"].append(execution_time)
                self.counters[f"{operation_name}_count"] += 1
                
    def track_value(self, metric_name: str, value: float):
        """跟踪数值指标"""
        with self.lock:
            self.metrics[metric_name].append(value)
            
    def increment_counter(self, counter_name: str, amount: int = 1):
        """增加计数器"""
        with self.lock:
            self.counters[counter_name] += amount
            
    def get_statistics(self, metric_name: str) -> Dict[str, float]:
        """获取统计信息"""
        with self.lock:
            values = list(self.metrics[metric_name])
            
        if not values:
            return {}
            
        return {
            'count': len(values),
            'mean': statistics.mean(values),
            'median': statistics.median(values),
            'min': min(values),
            'max': max(values),
            'std_dev': statistics.stdev(values) if len(values) > 1 else 0,
            'p95': statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values),
            'p99': statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
        }
        
    def get_all_metrics(self) -> Dict[str, Any]:
        """获取所有指标"""
        result = {}
        
        # 统计指标
        for metric_name in self.metrics:
            result[metric_name] = self.get_statistics(metric_name)
            
        # 计数器
        with self.lock:
            result['counters'] = dict(self.counters)
            
        return result

# 全局性能跟踪器
performance_tracker = PerformanceTracker()

def monitor_performance(operation_name: str):
    """性能监控装饰器"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with performance_tracker.track_execution_time(operation_name):
                return func(*args, **kwargs)
        return wrapper
    return decorator

# 使用示例
@monitor_performance("data_fetch")
def fetch_stock_data(symbol: str):
    """获取股票数据"""
    # 模拟数据获取
    time.sleep(0.1)
    return {"symbol": symbol, "price": 100.0}

@monitor_performance("strategy_calculation")
def calculate_strategy_signals(data):
    """计算策略信号"""
    # 模拟策略计算
    time.sleep(0.05)
    return {"signal": "buy"}
```

### 2. 数据库性能监控

```python
# monitor/db_monitor.py
import time
import logging
from typing import Dict, List
from contextlib import contextmanager
from sqlalchemy import event
from sqlalchemy.engine import Engine

class DatabaseMonitor:
    """数据库性能监控"""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # 慢查询阈值(秒)
        self.query_stats = defaultdict(list)
        self.logger = logging.getLogger(__name__)
        
    def setup_monitoring(self, engine: Engine):
        """设置数据库监控"""
        
        @event.listens_for(engine, "before_cursor_execute")
        def receive_before_cursor_execute(conn, cursor, statement,
                                        parameters, context, executemany):
            context._query_start_time = time.time()
            
        @event.listens_for(engine, "after_cursor_execute")
        def receive_after_cursor_execute(conn, cursor, statement,
                                       parameters, context, executemany):
            total_time = time.time() - context._query_start_time
            
            # 记录查询统计
            self._record_query_stats(statement, total_time)
            
            # 记录慢查询
            if total_time > self.slow_query_threshold:
                self._log_slow_query(statement, total_time, parameters)
                
    def _record_query_stats(self, statement: str, execution_time: float):
        """记录查询统计"""
        # 简化SQL语句用于分组
        simplified_query = self._simplify_query(statement)
        self.query_stats[simplified_query].append(execution_time)
        
        # 更新Prometheus指标
        from .metrics import performance_tracker
        performance_tracker.track_value('db_query_duration', execution_time)
        
    def _simplify_query(self, statement: str) -> str:
        """简化SQL语句"""
        # 移除参数值，保留查询模式
        import re
        # 替换数字和字符串字面量
        simplified = re.sub(r"'[^']*'", "'?'", statement)
        simplified = re.sub(r'\b\d+\b', '?', simplified)
        return simplified.strip()
        
    def _log_slow_query(self, statement: str, execution_time: float, 
                       parameters: Dict):
        """记录慢查询"""
        self.logger.warning(
            f"慢查询检测: 执行时间 {execution_time:.3f}s\n"
            f"SQL: {statement}\n"
            f"参数: {parameters}"
        )
        
        # 发送告警
        from .metrics import metrics_collector
        metrics_collector.track_value('slow_query_count', 1)
        
    def get_query_statistics(self) -> Dict[str, Dict]:
        """获取查询统计"""
        stats = {}
        
        for query, times in self.query_stats.items():
            if times:
                stats[query] = {
                    'count': len(times),
                    'avg_time': sum(times) / len(times),
                    'max_time': max(times),
                    'min_time': min(times),
                    'total_time': sum(times)
                }
                
        return stats
        
    def get_top_slow_queries(self, limit: int = 10) -> List[Dict]:
        """获取最慢查询列表"""
        query_stats = self.get_query_statistics()
        
        # 按平均执行时间排序
        sorted_queries = sorted(
            query_stats.items(),
            key=lambda x: x[1]['avg_time'],
            reverse=True
        )
        
        return [
            {
                'query': query,
                'stats': stats
            }
            for query, stats in sorted_queries[:limit]
        ]

# 全局数据库监控器
db_monitor = DatabaseMonitor()
```

## 🔄 持续监控

### 1. 健康检查

```python
# monitor/health_check.py
from typing import Dict, List, Optional
from datetime import datetime
import asyncio
import aiohttp
import psutil
import logging

class HealthChecker:
    """健康检查器"""
    
    def __init__(self):
        self.checks = {}
        self.logger = logging.getLogger(__name__)
        
    def register_check(self, name: str, check_func: callable, 
                      critical: bool = False, timeout: int = 30):
        """注册健康检查"""
        self.checks[name] = {
            'func': check_func,
            'critical': critical,
            'timeout': timeout,
            'last_result': None,
            'last_check': None
        }
        
    async def run_all_checks(self) -> Dict[str, Dict]:
        """运行所有健康检查"""
        results = {}
        
        for name, check_config in self.checks.items():
            try:
                result = await asyncio.wait_for(
                    self._run_single_check(check_config['func']),
                    timeout=check_config['timeout']
                )
                
                results[name] = {
                    'status': 'healthy' if result['healthy'] else 'unhealthy',
                    'message': result.get('message', ''),
                    'details': result.get('details', {}),
                    'critical': check_config['critical'],
                    'timestamp': datetime.now().isoformat()
                }
                
                # 更新缓存
                check_config['last_result'] = results[name]
                check_config['last_check'] = datetime.now()
                
            except asyncio.TimeoutError:
                results[name] = {
                    'status': 'timeout',
                    'message': f'健康检查超时 ({check_config["timeout"]}s)',
                    'critical': check_config['critical'],
                    'timestamp': datetime.now().isoformat()
                }
            except Exception as e:
                results[name] = {
                    'status': 'error',
                    'message': f'健康检查异常: {str(e)}',
                    'critical': check_config['critical'],
                    'timestamp': datetime.now().isoformat()
                }
                
        return results
        
    async def _run_single_check(self, check_func):
        """运行单个健康检查"""
        if asyncio.iscoroutinefunction(check_func):
            return await check_func()
        else:
            return check_func()
            
    def get_overall_status(self, check_results: Dict) -> str:
        """获取整体健康状态"""
        for check_name, result in check_results.items():
            if result['critical'] and result['status'] != 'healthy':
                return 'critical'
                
        # 检查是否有非关键服务不健康
        unhealthy_count = sum(1 for r in check_results.values() 
                            if r['status'] != 'healthy')
        
        if unhealthy_count == 0:
            return 'healthy'
        elif unhealthy_count <= len(check_results) * 0.2:  # 20%以下
            return 'degraded'
        else:
            return 'unhealthy'

# 具体健康检查实现
async def check_database_health():
    """检查数据库健康状态"""
    try:
        from data.database import get_database_manager
        db = get_database_manager()
        
        # 执行简单查询
        result = db.execute("SELECT 1")
        
        return {
            'healthy': True,
            'message': '数据库连接正常',
            'details': {'query_result': result}
        }
    except Exception as e:
        return {
            'healthy': False,
            'message': f'数据库连接失败: {str(e)}'
        }

async def check_redis_health():
    """检查Redis健康状态"""
    try:
        import redis
        r = redis.Redis(host='localhost', port=6379, db=0)
        
        # 执行ping命令
        result = r.ping()
        
        return {
            'healthy': result,
            'message': 'Redis连接正常' if result else 'Redis ping失败'
        }
    except Exception as e:
        return {
            'healthy': False,
            'message': f'Redis连接失败: {str(e)}'
        }

async def check_external_api_health():
    """检查外部API健康状态"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get('https://api.tushare.pro/health', 
                                 timeout=10) as response:
                if response.status == 200:
                    return {
                        'healthy': True,
                        'message': '外部API可访问',
                        'details': {'status_code': response.status}
                    }
                else:
                    return {
                        'healthy': False,
                        'message': f'外部API返回错误状态: {response.status}'
                    }
    except Exception as e:
        return {
            'healthy': False,
            'message': f'外部API检查失败: {str(e)}'
        }

def check_system_resources():
    """检查系统资源"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        issues = []
        if cpu_percent > 90:
            issues.append(f'CPU使用率过高: {cpu_percent:.1f}%')
        if memory.percent > 90:
            issues.append(f'内存使用率过高: {memory.percent:.1f}%')
        if disk.percent > 90:
            issues.append(f'磁盘使用率过高: {disk.percent:.1f}%')
            
        return {
            'healthy': len(issues) == 0,
            'message': '系统资源正常' if not issues else '; '.join(issues),
            'details': {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'disk_percent': disk.percent
            }
        }
    except Exception as e:
        return {
            'healthy': False,
            'message': f'系统资源检查失败: {str(e)}'
        }

# 设置健康检查
def setup_health_checks():
    """设置健康检查"""
    health_checker = HealthChecker()
    
    # 注册关键服务检查
    health_checker.register_check('database', check_database_health, critical=True)
    health_checker.register_check('redis', check_redis_health, critical=True)
    health_checker.register_check('system', check_system_resources, critical=True)
    
    # 注册非关键服务检查
    health_checker.register_check('external_api', check_external_api_health, critical=False)
    
    return health_checker
```

### 2. 自动化运维脚本

```bash
#!/bin/bash
# scripts/monitor_check.sh - 自动化监控检查脚本

set -e

LOG_FILE="/var/log/lianghua/monitor_check.log"
ALERT_WEBHOOK="http://localhost:5000/webhook/monitoring"

log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

check_service_status() {
    local service_name=$1
    if systemctl is-active --quiet "$service_name"; then
        log "✓ $service_name 服务运行正常"
        return 0
    else
        log "✗ $service_name 服务异常"
        return 1
    fi
}

check_application_health() {
    local url="http://localhost:5000/health"
    local response=$(curl -s -o /dev/null -w "%{http_code}" "$url" --max-time 10)
    
    if [ "$response" = "200" ]; then
        log "✓ 应用健康检查通过"
        return 0
    else
        log "✗ 应用健康检查失败 (HTTP $response)"
        return 1
    fi
}

check_disk_space() {
    local threshold=90
    local usage=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ "$usage" -lt "$threshold" ]; then
        log "✓ 磁盘空间正常 (使用率: ${usage}%)"
        return 0
    else
        log "✗ 磁盘空间不足 (使用率: ${usage}%)"
        return 1
    fi
}

check_memory_usage() {
    local threshold=90
    local usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100}')
    
    if [ "$usage" -lt "$threshold" ]; then
        log "✓ 内存使用正常 (使用率: ${usage}%)"
        return 0
    else
        log "✗ 内存使用过高 (使用率: ${usage}%)"
        return 1
    fi
}

check_log_errors() {
    local error_count=$(grep -c "ERROR" /var/log/lianghua/app.log 2>/dev/null || echo 0)
    local threshold=10
    
    if [ "$error_count" -lt "$threshold" ]; then
        log "✓ 应用错误日志正常 (错误数: $error_count)"
        return 0
    else
        log "✗ 应用错误日志过多 (错误数: $error_count)"
        return 1
    fi
}

send_alert() {
    local message="$1"
    local severity="$2"
    
    curl -X POST "$ALERT_WEBHOOK" \
         -H "Content-Type: application/json" \
         -d "{\"message\": \"$message\", \"severity\": \"$severity\"}" \
         --max-time 10 || log "告警发送失败"
}

main() {
    log "开始系统监控检查..."
    
    local failed_checks=0
    local check_results=()
    
    # 执行检查
    services=("mysql" "redis" "nginx")
    for service in "${services[@]}"; do
        if ! check_service_status "$service"; then
            failed_checks=$((failed_checks + 1))
            check_results+=("$service 服务异常")
        fi
    done
    
    if ! check_application_health; then
        failed_checks=$((failed_checks + 1))
        check_results+=("应用健康检查失败")
    fi
    
    if ! check_disk_space; then
        failed_checks=$((failed_checks + 1))
        check_results+=("磁盘空间不足")
    fi
    
    if ! check_memory_usage; then
        failed_checks=$((failed_checks + 1))
        check_results+=("内存使用过高")
    fi
    
    if ! check_log_errors; then
        failed_checks=$((failed_checks + 1))
        check_results+=("应用错误过多")
    fi
    
    # 汇总结果
    if [ "$failed_checks" -eq 0 ]; then
        log "✓ 所有检查项通过"
    else
        log "✗ $failed_checks 个检查项失败"
        
        # 发送告警
        alert_message="系统监控检查失败项: $(IFS=', '; echo "${check_results[*]}")"
        send_alert "$alert_message" "warning"
    fi
    
    log "监控检查完成"
}

# 运行检查
main "$@"
```

## 📱 运维面板

### 1. Web监控面板

```python
# monitor/admin_dashboard.py
from flask import Blueprint, render_template, jsonify, request
from flask_login import login_required
import asyncio
from .health_check import setup_health_checks
from .metrics import performance_tracker
from .db_monitor import db_monitor

admin_bp = Blueprint('admin', __name__, url_prefix='/admin')

@admin_bp.route('/dashboard')
@login_required
def dashboard():
    """监控仪表板主页"""
    return render_template('admin/dashboard.html')

@admin_bp.route('/api/system/health')
@login_required
def system_health():
    """系统健康状态API"""
    health_checker = setup_health_checks()
    
    # 运行健康检查
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        check_results = loop.run_until_complete(health_checker.run_all_checks())
        overall_status = health_checker.get_overall_status(check_results)
        
        return jsonify({
            'status': overall_status,
            'checks': check_results,
            'timestamp': datetime.now().isoformat()
        })
    finally:
        loop.close()

@admin_bp.route('/api/metrics/performance')
@login_required
def performance_metrics():
    """性能指标API"""
    metrics = performance_tracker.get_all_metrics()
    
    return jsonify({
        'metrics': metrics,
        'timestamp': datetime.now().isoformat()
    })

@admin_bp.route('/api/database/stats')
@login_required
def database_stats():
    """数据库统计API"""
    query_stats = db_monitor.get_query_statistics()
    slow_queries = db_monitor.get_top_slow_queries()
    
    return jsonify({
        'query_statistics': query_stats,
        'slow_queries': slow_queries,
        'timestamp': datetime.now().isoformat()
    })

@admin_bp.route('/api/alerts/active')
@login_required
def active_alerts():
    """活跃告警API"""
    # 从告警管理器获取活跃告警
    from .alert_handlers import alert_manager
    alerts = alert_manager.get_active_alerts()
    
    return jsonify({
        'alerts': [
            {
                'id': alert.alert_id,
                'rule_name': alert.rule_name,
                'severity': alert.severity.name,
                'status': alert.status.value,
                'created_at': alert.created_at.isoformat(),
                'message': alert.message
            }
            for alert in alerts
        ],
        'count': len(alerts)
    })

@admin_bp.route('/api/alerts/<alert_id>/acknowledge', methods=['POST'])
@login_required
def acknowledge_alert(alert_id):
    """确认告警"""
    from .alert_handlers import alert_manager
    from flask_login import current_user
    
    alert_manager.acknowledge_alert(alert_id, current_user.username)
    
    return jsonify({'status': 'success', 'message': '告警已确认'})

@admin_bp.route('/api/system/restart', methods=['POST'])
@login_required
def restart_system():
    """重启系统服务"""
    service = request.json.get('service')
    
    if service not in ['app', 'redis', 'nginx']:
        return jsonify({'status': 'error', 'message': '无效的服务名称'}), 400
    
    try:
        import subprocess
        if service == 'app':
            # 重启应用
            subprocess.run(['sudo', 'systemctl', 'restart', 'lianghua_vn'], check=True)
        else:
            subprocess.run(['sudo', 'systemctl', 'restart', service], check=True)
            
        return jsonify({'status': 'success', 'message': f'{service} 服务重启成功'})
    except subprocess.CalledProcessError as e:
        return jsonify({'status': 'error', 'message': f'服务重启失败: {str(e)}'}), 500
```

### 2. 运维工具脚本

```python
# scripts/ops_tools.py
#!/usr/bin/env python3
"""运维工具脚本"""

import click
import json
import requests
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

@click.group()
def cli():
    """量化交易系统运维工具"""
    pass

@cli.command()
@click.option('--days', default=7, help='查询天数')
def performance_report(days):
    """生成性能报告"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    click.echo(f"生成 {start_date.date()} 到 {end_date.date()} 的性能报告...")
    
    # 获取性能数据
    try:
        response = requests.get('http://localhost:5000/api/metrics/performance')
        response.raise_for_status()
        data = response.json()
        
        # 生成报告
        report = {
            'period': f"{start_date.date()} to {end_date.date()}",
            'summary': {
                'total_requests': data['metrics']['counters'].get('http_requests_count', 0),
                'avg_response_time': data['metrics'].get('http_request_duration', {}).get('mean', 0),
                'error_rate': calculate_error_rate(data['metrics'])
            },
            'timestamp': datetime.now().isoformat()
        }
        
        # 输出报告
        click.echo(json.dumps(report, indent=2, ensure_ascii=False))
        
    except Exception as e:
        click.echo(f"获取性能数据失败: {e}", err=True)

@cli.command()
@click.option('--service', required=True, help='服务名称')
def restart_service(service):
    """重启服务"""
    click.echo(f"重启服务: {service}")
    
    try:
        response = requests.post(
            'http://localhost:5000/api/system/restart',
            json={'service': service},
            headers={'Authorization': 'Bearer your_token'}
        )
        response.raise_for_status()
        result = response.json()
        
        if result['status'] == 'success':
            click.echo(f"✓ {result['message']}")
        else:
            click.echo(f"✗ {result['message']}", err=True)
            
    except Exception as e:
        click.echo(f"重启服务失败: {e}", err=True)

@cli.command()
def health_check():
    """执行健康检查"""
    click.echo("执行系统健康检查...")
    
    try:
        response = requests.get('http://localhost:5000/api/system/health')
        response.raise_for_status()
        data = response.json()
        
        click.echo(f"整体状态: {data['status']}")
        click.echo("\n检查详情:")
        
        for check_name, result in data['checks'].items():
            status_icon = "✓" if result['status'] == 'healthy' else "✗"
            critical_mark = " [关键]" if result['critical'] else ""
            
            click.echo(f"  {status_icon} {check_name}{critical_mark}: {result['message']}")
            
    except Exception as e:
        click.echo(f"健康检查失败: {e}", err=True)

@cli.command()
@click.option('--output', default='alerts.json', help='输出文件')
def export_alerts(output):
    """导出告警信息"""
    click.echo("导出告警信息...")
    
    try:
        response = requests.get('http://localhost:5000/api/alerts/active')
        response.raise_for_status()
        data = response.json()
        
        with open(output, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
            
        click.echo(f"告警信息已导出到 {output}")
        click.echo(f"活跃告警数量: {data['count']}")
        
    except Exception as e:
        click.echo(f"导出告警失败: {e}", err=True)

@cli.command()
@click.option('--period', default='1h', help='查询周期 (1h, 6h, 1d, 7d)')
def system_metrics(period):
    """查看系统指标"""
    click.echo(f"查询 {period} 的系统指标...")
    
    # 这里应该调用Prometheus API获取指标
    # 简化示例
    metrics = {
        'cpu_usage': 45.2,
        'memory_usage': 67.8,
        'disk_usage': 34.1,
        'network_in': '1.2MB/s',
        'network_out': '0.8MB/s'
    }
    
    click.echo("\n系统指标:")
    for metric, value in metrics.items():
        click.echo(f"  {metric}: {value}")

def calculate_error_rate(metrics):
    """计算错误率"""
    total_requests = metrics['counters'].get('http_requests_count', 0)
    error_requests = metrics['counters'].get('http_errors_count', 0)
    
    if total_requests > 0:
        return error_requests / total_requests
    return 0

if __name__ == '__main__':
    cli()
```

## 📋 运维检查清单

### 日常检查项目

#### 每日检查 (Daily Checklist)
- [ ] 系统健康状态检查
- [ ] 应用服务运行状态
- [ ] 数据库连接和性能
- [ ] 磁盘空间使用情况
- [ ] 内存和CPU使用率
- [ ] 网络连接状态
- [ ] 备份作业执行情况
- [ ] 告警消息处理
- [ ] 交易数据完整性
- [ ] 策略运行状态

#### 周度检查 (Weekly Checklist)
- [ ] 性能趋势分析
- [ ] 慢查询优化
- [ ] 日志轮转检查
- [ ] 安全更新检查
- [ ] 备份恢复测试
- [ ] 监控规则调优
- [ ] 容量规划评估
- [ ] 故障处理回顾

#### 月度检查 (Monthly Checklist)
- [ ] 系统容量评估
- [ ] 性能基线更新
- [ ] 灾备演练
- [ ] 安全审计
- [ ] 成本优化分析
- [ ] 运维流程改进
- [ ] 文档更新维护
- [ ] 团队技能培训

---

**文档版本**: v1.0  
**最后更新**: 2025年8月18日  
**维护团队**: 运维团队